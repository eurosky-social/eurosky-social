loki:
  auth_enabled: false

  commonConfig:
    replication_factor: 1

  storage:
    type: s3
    bucketNames:
      chunks: ${s3_bucket}
      ruler: ${s3_bucket}
    s3:
      endpoint: ${s3_endpoint}
      region: ${s3_region}
      accessKeyId: ${s3_access_key}
      secretAccessKey: ${s3_secret_key}
      s3ForcePathStyle: true
      insecure: false

  # Storage schema for compatibility
  schemaConfig:
    configs:
      - from: 2024-01-01
        store: tsdb
        object_store: s3
        schema: v13
        index:
          prefix: loki_index_
          period: 24h

  # Limits and retention
  limits_config:
    retention_period: 168h # 7 days in Loki (then moved to S3)
    max_query_lookback: 720h # 30 days max query range
    ingestion_rate_mb: 10
    ingestion_burst_size_mb: 20
    per_stream_rate_limit: 5MB
    per_stream_rate_limit_burst: 15MB

  # Compactor for retention enforcement
  compactor:
    retention_enabled: true
    delete_request_store: s3
    retention_delete_delay: 2h
    retention_delete_worker_count: 150

  ingester:
    # WAL survives pod/node crashes, fails only with PVC corruption/loss
    wal:
      enabled: true
      dir: /var/loki/wal
      flush_on_shutdown: true

  # TODO: Reduce RPO from current 30-60min to 5-10min
  # Current RPO: Logs in the PVC are at risk until uploaded to S3 (~30-60min)
  # To reduce data loss window, uncomment below (trade-off: higher S3 API costs)
  # ingester:
  #   chunk_idle_period: 5m       # Flush chunks idle for 5min (default: 30m)
  #   max_chunk_age: 10m          # Force flush after 10min (default: 1h)
  #   chunk_target_size: 524288   # 512KB chunks (default: 1.5MB) - smaller = faster flush

# Deployment mode: single binary for simplicity (dev/small-scale)
# TODO: Switch to microservices mode for production HA (official Grafana recommendation)
# TODO: Evaluate scalable mode vs microservices mode based on query/write load patterns
deploymentMode: SingleBinary

singleBinary:
  replicas: 1 # TODO: Increase to 2+ for HA (requires shared S3 state + proper locking)
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi

  persistence:
    enabled: true
    storageClass: ${storage_class}
    size: 10Gi # TODO: Increase to 30Gi+ for production (stores WAL + index before S3 upload)

  # TODO: Enable WAL (write-ahead log) for ingester durability
  # TODO: Add topologySpreadConstraints for multi-AZ distribution
  # TODO: Add podAntiAffinity or use topologySpreadConstraints for replica spreading
  # TODO: Add lifecycle.preStop hook for graceful shutdown (flush chunks to S3)
  # TODO: Configure terminationGracePeriodSeconds based on chunk flush time

# Gateway (nginx) - disabled for SingleBinary mode (not needed for internal cluster access)
gateway:
  enabled: false # Disable to save resources and avoid DNS resolver issues

# Caching - disabled for SingleBinary mode (causes memory pressure on small clusters)
chunksCache:
  enabled: false

resultsCache:
  enabled: false

# Backend storage for index/cache
backend:
  replicas: 0 # Not used in SingleBinary mode

# Read/Write components
read:
  replicas: 0 # Not used in SingleBinary mode

write:
  replicas: 0 # Not used in SingleBinary mode

# Monitoring
monitoring:
  selfMonitoring:
    enabled: false
    grafanaAgent:
      installOperator: false

  serviceMonitor:
    enabled: true # Auto-discovered by Prometheus

  lokiCanary:
    enabled: false # Disabled to save resources on small cluster

# TODO: Enable ingress with TLS for external Loki queries (optional - for federated log querying)
# TODO: Configure PrometheusRules for Loki self-monitoring (errors, high cardinality, ingestion failures, disk space)
# TODO: Add NetworkPolicy to restrict access to Loki (allow only Promtail, Grafana, Prometheus)
# TODO: Configure limits_config.max_streams_per_user to prevent cardinality explosion
# TODO: Add security context (runAsNonRoot, readOnlyRootFilesystem where possible)
# TODO: Rotate S3 credentials via external secret management (Scaleway Secret Manager or Sealed Secrets)
# TODO: Enable Loki query frontend caching for better dashboard performance (requires Redis/Memcached)
